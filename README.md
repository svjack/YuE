<p align="center">
    <img src="./assets/logo/ç™½åº•.png" width="400" />
</p>

```bash
sudo apt-get update && sudo apt-get install cbm ffmpeg git-lfs

conda create -n yue python=3.10 # Python >=3.8 is recommended.
conda activate yue
pip install ipykernel
python -m ipykernel install --user --name yue --display-name "yue"

# install cuda >= 11.8
#conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia

git clone https://huggingface.co/spaces/svjack/YuE && cd YuE
pip install -r requirements.txt
pip install flash-attn --no-build-isolation

python app.py
### Ctrl + C

cd inference
python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-en-cot \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics.txt \
    --run_n_segments 2 \
    --stage2_batch_size 4 \
    --output_dir ./output \
    --cuda_idx 0 \
    --max_new_tokens 3000

# ffmpeg -i output/cot_inspiring-female-uplifting-pop-airy-vocal-electronic-bright-vocal-vocal_tp0@93_T100_rp102_maxtk3000_mixed_f5e0c515-f10c-4a13-a47d-76c6cc1712fd.mp3' -c:v libx264 -c:a aac -strict experimental output/cot_inspiring-female-uplifting-pop-airy-vocal-electronic-bright-vocal-vocal_tp0@93__T1@0_rp1@2_maxtk3000_mixed_{5e0c515-f10c-4a13-a47d-76c6cc1712fd.mp4
```


https://github.com/user-attachments/assets/30f53d32-efc3-4dde-8d58-68ecf9c8ec19


```bash
python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-zh-cot \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics_zh.txt \
    --run_n_segments 2 \
    --stage2_batch_size 4 \
    --output_dir ./zh_output \
    --cuda_idx 0 \
    --max_new_tokens 3000

python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-zh-cot \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics_zh.txt \
    --run_n_segments 2 \
    --stage2_batch_size 4 \
    --output_dir ./zh_output_new \
    --cuda_idx 0 \
    --max_new_tokens 3000 \
    --prompt_end_time 360

python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-zh-cot \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics_zh.txt \
    --run_n_segments 20 \
    --stage2_batch_size 4 \
    --output_dir ./zh_output_long \
    --cuda_idx 0 \
    --max_new_tokens 3000 \
    --prompt_end_time 360

# ffmpeg -i cot_zh_demo.mp3-codec:a libmp3lame -b:a 192k -f mp4 -vn cot_zh_demo.mp4
```

```txt
[verse]
æ³¨ç›®å¤•é˜³æ™šï¼Œå½©éœæ»¡å¤©è¾¹
æ€å¿µç»•å¿ƒé—´ï¼Œæ— æ³•æŠ—æ‹’çš„æƒ…æ„Ÿ
æ˜çŸ¥æ›¾ä»¤ä½ å¤±æœ›ï¼Œè¿‡é”™åœ¨çœ¼å‰
æ­¤åˆ»å½’æ¥åªä¸ºï¼Œä¿®è¡¥æ°´ç—•æ¶Ÿæ¶Ÿ

[chorus]
æ— è®ºä½ é€‰æ‹©ä½•è·¯ï¼Œæˆ‘åœ¨èº«åç´§å®ˆæŠ¤
è¿½é€ä½ çš„æ¢¦æƒ³ï¼Œæ¡ä½å¸Œæœ›ä¸å…‰
æ­¤æƒ…æ­¤æ„æ­¤åˆ»ï¼Œéš¾ä»¥æŠµæ‹’
æˆ‘å·²å†³ç»ï¼Œä¸åº”é€€ç¼©
æ·±çŸ¥ä½ æ— æ³•æŠµæŠ—ï¼Œæˆ‘ä¸ä¼šé€€ç¼©

[verse]
æœ‰äººç¬‘æˆ‘æ„šï¼Œä¸ºçˆ±ç‹¬è‡ªè¿½é€
è¿™èˆ¬çš„æ·±æƒ…ï¼Œå”¯ä½ æˆ‘å¿ƒç…§ä¸è¯¯
å¿ƒä¹‹æ‰€å‘ï¼Œå”¯ä½ ä¸€äºº
ä¸æ„¿ä½ è¿œå»ï¼Œæˆ‘æ—©å·²å¿ƒæœ‰æ‰€å±
```



https://github.com/user-attachments/assets/42822b4d-2f7d-4380-8ecf-4d46d3c99dfb





https://github.com/user-attachments/assets/137e2bd0-7812-471d-bffd-da863a0234a4




https://github.com/user-attachments/assets/300e0554-551f-4ed7-9dad-0cbf48ca9d54



```python
# å®šä¹‰è¯æ•°æ®
lyrics_data = {
    "è‹è½¼_æ°´è°ƒæ­Œå¤´": """[verse]
æ˜æœˆå‡ æ—¶æœ‰ï¼ŸæŠŠé…’é—®é’å¤©ã€‚
ä¸çŸ¥å¤©ä¸Šå®«é˜™ï¼Œä»Šå¤•æ˜¯ä½•å¹´ã€‚
æˆ‘æ¬²ä¹˜é£å½’å»ï¼Œåˆæç¼æ¥¼ç‰å®‡ï¼Œé«˜å¤„ä¸èƒœå¯’ã€‚
èµ·èˆå¼„æ¸…å½±ï¼Œä½•ä¼¼åœ¨äººé—´ã€‚

[chorus]
ä¸åº”æœ‰æ¨ï¼Œä½•äº‹é•¿å‘åˆ«æ—¶åœ†ï¼Ÿ
äººæœ‰æ‚²æ¬¢ç¦»åˆï¼Œæœˆæœ‰é˜´æ™´åœ†ç¼ºï¼Œæ­¤äº‹å¤éš¾å…¨ã€‚
ä½†æ„¿äººé•¿ä¹…ï¼Œåƒé‡Œå…±å©µå¨Ÿ.

[outro]
""",

    "è¾›å¼ƒç–¾_é’ç‰æ¡ˆ": """[verse]
ä¸œé£å¤œæ”¾èŠ±åƒæ ‘ï¼Œæ›´å¹è½ã€æ˜Ÿå¦‚é›¨ã€‚
å®é©¬é›•è½¦é¦™æ»¡è·¯ã€‚
å‡¤ç®«å£°åŠ¨ï¼Œç‰å£¶å…‰è½¬ï¼Œä¸€å¤œé±¼é¾™èˆã€‚

[chorus]
è›¾å„¿é›ªæŸ³é»„é‡‘ç¼•ï¼Œç¬‘è¯­ç›ˆç›ˆæš—é¦™å»ã€‚
ä¼—é‡Œå¯»ä»–åƒç™¾åº¦ï¼Œè“¦ç„¶å›é¦–ï¼Œé‚£äººå´åœ¨ï¼Œç¯ç«é˜‘çŠå¤„.

[outro]""",

    "ææ¸…ç…§_å£°å£°æ…¢": """[verse]
å¯»å¯»è§…è§…ï¼Œå†·å†·æ¸…æ¸…ï¼Œå‡„å‡„æƒ¨æƒ¨æˆšæˆšã€‚
ä¹æš–è¿˜å¯’æ—¶å€™ï¼Œæœ€éš¾å°†æ¯ã€‚
ä¸‰æ¯ä¸¤ç›æ·¡é…’ï¼Œæ€æ•Œä»–ã€æ™šæ¥é£æ€¥ï¼

[chorus]
æ»¡åœ°é»„èŠ±å †ç§¯ï¼Œæ†”æ‚´æŸï¼Œå¦‚ä»Šæœ‰è°å ªæ‘˜ï¼Ÿ
å®ˆç€çª—å„¿ï¼Œç‹¬è‡ªæ€ç”Ÿå¾—é»‘ï¼
æ¢§æ¡æ›´å…¼ç»†é›¨ï¼Œåˆ°é»„æ˜ã€ç‚¹ç‚¹æ»´æ»´.

[outro]""",

    "å²³é£_æ»¡æ±Ÿçº¢": """[verse]
æ€’å‘å†²å† ï¼Œå‡­æ å¤„ã€æ½‡æ½‡é›¨æ­‡ã€‚
æŠ¬æœ›çœ¼ã€ä»°å¤©é•¿å•¸ï¼Œå£®æ€€æ¿€çƒˆã€‚
ä¸‰ååŠŸåå°˜ä¸åœŸï¼Œå…«åƒé‡Œè·¯äº‘å’Œæœˆã€‚

[chorus]
é–åº·è€»ï¼ŒçŠ¹æœªé›ªã€‚
é©±é•¿è½¦è¸ç ´ï¼Œè´ºå…°å±±ç¼ºã€‚
å£®å¿—é¥¥é¤èƒ¡è™è‚‰ï¼Œç¬‘è°ˆæ¸´é¥®åŒˆå¥´è¡€ã€‚
å¾…ä»å¤´ã€æ”¶æ‹¾æ—§å±±æ²³ï¼Œæœå¤©é˜™ï¼

[outro]""",

    "è‹è½¼_å¿µå¥´å¨‡": """[verse]
å¤§æ±Ÿä¸œå»ï¼Œæµªæ·˜å°½ï¼Œåƒå¤é£æµäººç‰©ã€‚
æ•…å’è¥¿è¾¹ï¼Œäººé“æ˜¯ï¼Œä¸‰å›½å‘¨éƒèµ¤å£ã€‚
ä¹±çŸ³ç©¿ç©ºï¼ŒæƒŠæ¶›æ‹å²¸ï¼Œå·èµ·åƒå †é›ªã€‚

[chorus]
é¥æƒ³å…¬ç‘¾å½“å¹´ï¼Œå°ä¹”åˆå«äº†ï¼Œé›„å§¿è‹±å‘ã€‚
ç¾½æ‰‡çº¶å·¾ï¼Œè°ˆç¬‘é—´ï¼Œæ¨¯æ©¹ç°é£çƒŸç­ã€‚
æ•…å›½ç¥æ¸¸ï¼Œå¤šæƒ…åº”ç¬‘æˆ‘ï¼Œæ—©ç”Ÿåå‘.

[outro]""",

    "è¾›å¼ƒç–¾_æ°¸é‡ä¹": """[verse]
åƒå¤æ±Ÿå±±ï¼Œè‹±é›„æ— è§…å­™ä»²è°‹å¤„ã€‚
èˆæ¦­æ­Œå°ï¼Œé£æµæ€»è¢«é›¨æ‰“é£å¹å»ã€‚
æ–œé˜³è‰æ ‘ï¼Œå¯»å¸¸å··é™Œï¼Œäººé“å¯„å¥´æ›¾ä½ã€‚

[chorus]
æƒ³å½“å¹´ï¼Œé‡‘æˆˆé“é©¬ï¼Œæ°”åä¸‡é‡Œå¦‚è™ã€‚
å››åä¸‰å¹´ï¼Œæœ›ä¸­çŠ¹è®°ï¼Œçƒ½ç«æ‰¬å·è·¯ã€‚
å¯å ªå›é¦–ï¼Œä½›ç‹¸ç¥ ä¸‹ï¼Œä¸€ç‰‡ç¥é¸¦ç¤¾é¼“.

[outro]""",

    "è¾›å¼ƒç–¾_ç ´é˜µå­": """[verse]
é†‰é‡ŒæŒ‘ç¯çœ‹å‰‘ï¼Œæ¢¦å›å¹è§’è¿è¥ã€‚
å…«ç™¾é‡Œåˆ†éº¾ä¸‹ç‚™ï¼Œäº”åå¼¦ç¿»å¡å¤–å£°ã€‚

[chorus]
æ²™åœºç§‹ç‚¹å…µã€‚
äº†å´å›ç‹å¤©ä¸‹äº‹ï¼Œèµ¢å¾—ç”Ÿå‰èº«ååã€‚
å¯æ€œç™½å‘ç”Ÿï¼

[outro]""",

    "ææ¸…ç…§_å¦‚æ¢¦ä»¤": """[verse]
å¸¸è®°æºªäº­æ—¥æš®ï¼Œæ²‰é†‰ä¸çŸ¥å½’è·¯ã€‚
å…´å°½æ™šå›èˆŸï¼Œè¯¯å…¥è—•èŠ±æ·±å¤„ã€‚

[chorus]
äº‰æ¸¡ï¼Œäº‰æ¸¡ï¼ŒæƒŠèµ·ä¸€æ»©é¸¥é¹­.

[outro]""",

    "æ¸©åº­ç­ _è©è¨è›®": """[verse]
å°å±±é‡å é‡‘æ˜ç­ï¼Œé¬“äº‘æ¬²åº¦é¦™è…®é›ªã€‚
æ‡’èµ·ç”»è›¾çœ‰ï¼Œå¼„å¦†æ¢³æ´—è¿Ÿã€‚

[chorus]
ç…§èŠ±å‰åé•œï¼ŒèŠ±é¢äº¤ç›¸æ˜ ã€‚
æ–°å¸–ç»£ç½—è¥¦ï¼ŒåŒåŒé‡‘é¹§é¸ª.

[outro]""",

    "æ¨æ…_ä¸´æ±Ÿä»™": """[verse]
æ»šæ»šé•¿æ±Ÿä¸œé€æ°´ï¼ŒæµªèŠ±æ·˜å°½è‹±é›„ã€‚
æ˜¯éæˆè´¥è½¬å¤´ç©ºã€‚
é’å±±ä¾æ—§åœ¨ï¼Œå‡ åº¦å¤•é˜³çº¢ã€‚

[chorus]
ç™½å‘æ¸”æ¨µæ±Ÿæ¸šä¸Šï¼Œæƒ¯çœ‹ç§‹æœˆæ˜¥é£ã€‚
ä¸€å£¶æµŠé…’å–œç›¸é€¢ã€‚
å¤ä»Šå¤šå°‘äº‹ï¼Œéƒ½ä»˜ç¬‘è°ˆä¸­ã€‚

[outro]"""
}

lyrics_data = {
    "è‹è½¼_æ°´è°ƒæ­Œå¤´": """[verse]
æ˜æœˆå‡ æ—¶æœ‰ï¼ŸæŠŠé…’é—®é’å¤©ã€‚
ä¸çŸ¥å¤©ä¸Šå®«é˜™ï¼Œä»Šå¤•æ˜¯ä½•å¹´ã€‚
æˆ‘æ¬²ä¹˜é£å½’å»ï¼Œåˆæç¼æ¥¼ç‰å®‡ï¼Œé«˜å¤„ä¸èƒœå¯’ã€‚
èµ·èˆå¼„æ¸…å½±ï¼Œä½•ä¼¼åœ¨äººé—´ã€‚
ä¸åº”æœ‰æ¨ï¼Œä½•äº‹é•¿å‘åˆ«æ—¶åœ†ï¼Ÿ
äººæœ‰æ‚²æ¬¢ç¦»åˆï¼Œæœˆæœ‰é˜´æ™´åœ†ç¼ºï¼Œæ­¤äº‹å¤éš¾å…¨ã€‚
ä½†æ„¿äººé•¿ä¹…ï¼Œåƒé‡Œå…±å©µå¨Ÿ.

[chorus]

[outro]
""",

    "è¾›å¼ƒç–¾_é’ç‰æ¡ˆ": """[verse]
ä¸œé£å¤œæ”¾èŠ±åƒæ ‘ï¼Œæ›´å¹è½ã€æ˜Ÿå¦‚é›¨ã€‚
å®é©¬é›•è½¦é¦™æ»¡è·¯ã€‚
å‡¤ç®«å£°åŠ¨ï¼Œç‰å£¶å…‰è½¬ï¼Œä¸€å¤œé±¼é¾™èˆã€‚
è›¾å„¿é›ªæŸ³é»„é‡‘ç¼•ï¼Œç¬‘è¯­ç›ˆç›ˆæš—é¦™å»ã€‚
ä¼—é‡Œå¯»ä»–åƒç™¾åº¦ï¼Œè“¦ç„¶å›é¦–ï¼Œé‚£äººå´åœ¨ï¼Œç¯ç«é˜‘çŠå¤„.

[chorus]

[outro]""",

    "ææ¸…ç…§_å£°å£°æ…¢": """[verse]
å¯»å¯»è§…è§…ï¼Œå†·å†·æ¸…æ¸…ï¼Œå‡„å‡„æƒ¨æƒ¨æˆšæˆšã€‚
ä¹æš–è¿˜å¯’æ—¶å€™ï¼Œæœ€éš¾å°†æ¯ã€‚
ä¸‰æ¯ä¸¤ç›æ·¡é…’ï¼Œæ€æ•Œä»–ã€æ™šæ¥é£æ€¥ï¼
æ»¡åœ°é»„èŠ±å †ç§¯ï¼Œæ†”æ‚´æŸï¼Œå¦‚ä»Šæœ‰è°å ªæ‘˜ï¼Ÿ
å®ˆç€çª—å„¿ï¼Œç‹¬è‡ªæ€ç”Ÿå¾—é»‘ï¼
æ¢§æ¡æ›´å…¼ç»†é›¨ï¼Œåˆ°é»„æ˜ã€ç‚¹ç‚¹æ»´æ»´.

[chorus]

[outro]""",

    "å²³é£_æ»¡æ±Ÿçº¢": """[verse]
æ€’å‘å†²å† ï¼Œå‡­æ å¤„ã€æ½‡æ½‡é›¨æ­‡ã€‚
æŠ¬æœ›çœ¼ã€ä»°å¤©é•¿å•¸ï¼Œå£®æ€€æ¿€çƒˆã€‚
ä¸‰ååŠŸåå°˜ä¸åœŸï¼Œå…«åƒé‡Œè·¯äº‘å’Œæœˆã€‚
é–åº·è€»ï¼ŒçŠ¹æœªé›ªã€‚
é©±é•¿è½¦è¸ç ´ï¼Œè´ºå…°å±±ç¼ºã€‚
å£®å¿—é¥¥é¤èƒ¡è™è‚‰ï¼Œç¬‘è°ˆæ¸´é¥®åŒˆå¥´è¡€ã€‚
å¾…ä»å¤´ã€æ”¶æ‹¾æ—§å±±æ²³ï¼Œæœå¤©é˜™ï¼

[chorus]

[outro]""",

    "è‹è½¼_å¿µå¥´å¨‡": """[verse]
å¤§æ±Ÿä¸œå»ï¼Œæµªæ·˜å°½ï¼Œåƒå¤é£æµäººç‰©ã€‚
æ•…å’è¥¿è¾¹ï¼Œäººé“æ˜¯ï¼Œä¸‰å›½å‘¨éƒèµ¤å£ã€‚
ä¹±çŸ³ç©¿ç©ºï¼ŒæƒŠæ¶›æ‹å²¸ï¼Œå·èµ·åƒå †é›ªã€‚
é¥æƒ³å…¬ç‘¾å½“å¹´ï¼Œå°ä¹”åˆå«äº†ï¼Œé›„å§¿è‹±å‘ã€‚
ç¾½æ‰‡çº¶å·¾ï¼Œè°ˆç¬‘é—´ï¼Œæ¨¯æ©¹ç°é£çƒŸç­ã€‚
æ•…å›½ç¥æ¸¸ï¼Œå¤šæƒ…åº”ç¬‘æˆ‘ï¼Œæ—©ç”Ÿåå‘.

[chorus]

[outro]""",

    "è¾›å¼ƒç–¾_æ°¸é‡ä¹": """[verse]
åƒå¤æ±Ÿå±±ï¼Œè‹±é›„æ— è§…å­™ä»²è°‹å¤„ã€‚
èˆæ¦­æ­Œå°ï¼Œé£æµæ€»è¢«é›¨æ‰“é£å¹å»ã€‚
æ–œé˜³è‰æ ‘ï¼Œå¯»å¸¸å··é™Œï¼Œäººé“å¯„å¥´æ›¾ä½ã€‚
æƒ³å½“å¹´ï¼Œé‡‘æˆˆé“é©¬ï¼Œæ°”åä¸‡é‡Œå¦‚è™ã€‚
å››åä¸‰å¹´ï¼Œæœ›ä¸­çŠ¹è®°ï¼Œçƒ½ç«æ‰¬å·è·¯ã€‚
å¯å ªå›é¦–ï¼Œä½›ç‹¸ç¥ ä¸‹ï¼Œä¸€ç‰‡ç¥é¸¦ç¤¾é¼“.

[chorus]

[outro]""",

    "è¾›å¼ƒç–¾_ç ´é˜µå­": """[verse]
é†‰é‡ŒæŒ‘ç¯çœ‹å‰‘ï¼Œæ¢¦å›å¹è§’è¿è¥ã€‚
å…«ç™¾é‡Œåˆ†éº¾ä¸‹ç‚™ï¼Œäº”åå¼¦ç¿»å¡å¤–å£°ã€‚
æ²™åœºç§‹ç‚¹å…µã€‚
äº†å´å›ç‹å¤©ä¸‹äº‹ï¼Œèµ¢å¾—ç”Ÿå‰èº«ååã€‚
å¯æ€œç™½å‘ç”Ÿï¼

[chorus]

[outro]""",

    "ææ¸…ç…§_å¦‚æ¢¦ä»¤": """[verse]
å¸¸è®°æºªäº­æ—¥æš®ï¼Œæ²‰é†‰ä¸çŸ¥å½’è·¯ã€‚
å…´å°½æ™šå›èˆŸï¼Œè¯¯å…¥è—•èŠ±æ·±å¤„ã€‚
äº‰æ¸¡ï¼Œäº‰æ¸¡ï¼ŒæƒŠèµ·ä¸€æ»©é¸¥é¹­.

[chorus]

[outro]""",

    "æ¸©åº­ç­ _è©è¨è›®": """[verse]
å°å±±é‡å é‡‘æ˜ç­ï¼Œé¬“äº‘æ¬²åº¦é¦™è…®é›ªã€‚
æ‡’èµ·ç”»è›¾çœ‰ï¼Œå¼„å¦†æ¢³æ´—è¿Ÿã€‚
ç…§èŠ±å‰åé•œï¼ŒèŠ±é¢äº¤ç›¸æ˜ ã€‚
æ–°å¸–ç»£ç½—è¥¦ï¼ŒåŒåŒé‡‘é¹§é¸ª.

[chorus]

[outro]""",

    "æ¨æ…_ä¸´æ±Ÿä»™": """[verse]
æ»šæ»šé•¿æ±Ÿä¸œé€æ°´ï¼ŒæµªèŠ±æ·˜å°½è‹±é›„ã€‚
æ˜¯éæˆè´¥è½¬å¤´ç©ºã€‚
é’å±±ä¾æ—§åœ¨ï¼Œå‡ åº¦å¤•é˜³çº¢ã€‚
ç™½å‘æ¸”æ¨µæ±Ÿæ¸šä¸Šï¼Œæƒ¯çœ‹ç§‹æœˆæ˜¥é£ã€‚
ä¸€å£¶æµŠé…’å–œç›¸é€¢ã€‚
å¤ä»Šå¤šå°‘äº‹ï¼Œéƒ½ä»˜ç¬‘è°ˆä¸­ã€‚

[chorus]

[outro]"""
}

# å°†å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶
for filename, content in lyrics_data.items():
    # åˆ›å»ºæ–‡ä»¶å
    file_name = f"lyrics_{filename}.txt"
    with open(file_name, "w", encoding="utf-8") as file:
        file.write(content)
    print(f"æ–‡ä»¶å·²ç”Ÿæˆ: {file_name}")

print("æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")

```

```bash
#!/bin/bash

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p ./zh_output_song_short

# éå† lyrics_*.txt æ–‡ä»¶
for lyrics_file in lyrics_*.txt; do
    # å¤åˆ¶å½“å‰ lyrics æ–‡ä»¶åˆ° lyrics_zh.txt
    cp "$lyrics_file" lyrics_zh.txt
    
    # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œç”¨äºå‘½åè¾“å‡ºç›®å½•
    output_dir_name=$(basename "$lyrics_file" .txt)
    output_dir=./zh_output_song_short/"$output_dir_name"
    
    echo "Processing $lyrics_file..."
    echo "Output directory: $output_dir"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$output_dir"
    
    python infer.py \
        --stage1_model m-a-p/YuE-s1-7B-anneal-zh-cot \
        --stage2_model m-a-p/YuE-s2-1B-general \
        --genre_txt genre.txt \
        --lyrics_txt lyrics_zh.txt \
        --run_n_segments 4 \
        --stage2_batch_size 4 \
        --output_dir "$output_dir" \
        --cuda_idx 0 \
        --max_new_tokens 3000 \
        --prompt_end_time 3600 \
        
done

echo "Processing completed!"
```

```python
import os
from datasets import Dataset, Audio

# å®šä¹‰æ­Œè¯æ–‡ä»¶è·¯å¾„å’ŒéŸ³ä¹æ–‡ä»¶è¾“å‡ºè·¯å¾„
lyrics_dir = "."  # æ­Œè¯æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
music_dir = "./zh_output_song_short"  # éŸ³ä¹æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•

# åˆå§‹åŒ–æ•°æ®é›†åˆ—è¡¨
data = []

# éå†æ­Œè¯æ–‡ä»¶
for lyrics_file in os.listdir(lyrics_dir):
    if lyrics_file.startswith("lyrics_") and lyrics_file.endswith(".txt") and "zh" not in lyrics_file:
        # æå–ä½œè€…å’Œè¯ç‰Œå
        filename = lyrics_file[len("lyrics_"):-len(".txt")]
        author, title = filename.split("_", 1)
        
        # è¯»å–æ­Œè¯å†…å®¹
        with open(os.path.join(lyrics_dir, lyrics_file), "r", encoding="utf-8") as f:
            lyrics_content = f.read()
        
        # æ„å»ºéŸ³ä¹æ–‡ä»¶è·¯å¾„
        music_subdir = os.path.join(music_dir, f"lyrics_{filename}")
        
        # æ£€æŸ¥éŸ³ä¹å­ç›®å½•æ˜¯å¦å­˜åœ¨
        if os.path.exists(music_subdir):
            # æŸ¥æ‰¾éŸ³ä¹æ–‡ä»¶
            music_files = [f for f in os.listdir(music_subdir) if f.endswith(".wav") or f.endswith(".mp3")]
            
            # å¦‚æœæ‰¾åˆ°éŸ³ä¹æ–‡ä»¶ï¼Œåˆ™æ·»åŠ åˆ°æ•°æ®é›†
            if music_files:
                music_file = os.path.join(music_subdir, music_files[0])
                # ä½¿ç”¨ Audio ç±»å‹ä¿å­˜éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                #music_content = {"path": music_file, "array": None, "sampling_rate": None}
                
                # æ·»åŠ åˆ°æ•°æ®é›†
                data.append({
                    "author": author,
                    "title": title,
                    "lyrics": lyrics_content,
                    "music": music_file
                })
        else:
            print(f"éŸ³ä¹å­ç›®å½•ä¸å­˜åœ¨: {music_subdir}")

# åˆ›å»º Hugging Face Dataset
if data:  # ç¡®ä¿æ•°æ®åˆ—è¡¨ä¸ä¸ºç©º
    dataset = Dataset.from_dict({
        "author": [item["author"] for item in data],
        "title": [item["title"] for item in data],
        "lyrics": [item["lyrics"] for item in data],
        "music": [item["music"] for item in data]
    })

    # å°† music åˆ—è½¬æ¢ä¸º Audio ç±»å‹
    dataset = dataset.cast_column("music", Audio())

    # ä¿å­˜æ•°æ®é›†åˆ°ç£ç›˜
    dataset.save_to_disk("./lyrics_music_dataset")
    print("æ•°æ®é›†å·²ä¿å­˜åˆ° ./lyrics_music_dataset")
else:
    print("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¯ä»¥ç”Ÿæˆæ•°æ®é›†ã€‚")

dataset.push_to_hub("svjack/YuE-Song-Ci-9")
```

<p align="center">
    <a href="https://map-yue.github.io/">Demo ğŸ¶</a> &nbsp;|&nbsp; ğŸ“‘ <a href="">Paper (coming soon)</a>
    <br>
    <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-cot">YuE-s1-7B-anneal-en-cot ğŸ¤—</a> &nbsp;|&nbsp; <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-en-icl">YuE-s1-7B-anneal-en-icl ğŸ¤—</a> &nbsp;|&nbsp; <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-jp-kr-cot">YuE-s1-7B-anneal-jp-kr-cot ğŸ¤—</a>
    <br>
    <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-jp-kr-icl">YuE-s1-7B-anneal-jp-kr-icl ğŸ¤—</a> &nbsp;|&nbsp; <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-zh-cot">YuE-s1-7B-anneal-zh-cot ğŸ¤—</a> &nbsp;|&nbsp; <a href="https://huggingface.co/m-a-p/YuE-s1-7B-anneal-zh-icl">YuE-s1-7B-anneal-zh-icl ğŸ¤—</a>
    <br>
    <a href="https://huggingface.co/m-a-p/YuE-s2-1B-general">YuE-s2-1B-general ğŸ¤—</a> &nbsp;|&nbsp; <a href="https://huggingface.co/m-a-p/YuE-upsampler">YuE-upsampler ğŸ¤—</a>
</p>

---
Our model's name is **YuE (ä¹)**. In Chinese, the word means "music" and "happiness." Some of you may find words that start with Yu hard to pronounce. If so, you can just call it "yeah." We wrote a song with our model's name, see [here](assets/logo/yue.mp3).

YuE is a groundbreaking series of open-source foundation models designed for music generation, specifically for transforming lyrics into full songs (lyrics2song). It can generate a complete song, lasting several minutes, that includes both a catchy vocal track and accompaniment track. YuE is capable of modeling diverse genres/languages/vocal techniques. Please visit the [**Demo Page**](https://map-yue.github.io/) for amazing vocal performance.

## News and Updates

* **2025.01.29 ğŸ‰**: We have updated the license description. we **ENCOURAGE** artists and content creators to sample and incorporate outputs generated by our model into their own works, and even monetize them. The only requirement is to credit our name: **YuE by M-A-P**.
* **2025.01.28 ğŸ«¶**: Thanks to Fahd for creating a tutorial on how to quickly get started with YuE. Here is his [demonstration](https://www.youtube.com/watch?v=RSMNH9GitbA).
* **2025.01.26 ğŸ”¥**: We have released the **YuE** series.

<br>

---
## TODOs
- [ ] Support dual-track ICL mode.
- [ ] Support gradio interface.
- [ ] Support transformers tensor parallel.
- [ ] Online serving on huggingface space.
- [ ] Example finetune code for enabling BPM control using ğŸ¤— Transformers.

---

## Hardware and Performance

### **GPU Memory**
YuE requires significant GPU memory for generating long sequences. Below are the recommended configurations:

- **For GPUs with 24GB memory or less**: Run **up to 2 sessions** concurrently to avoid out-of-memory (OOM) errors.
- **For full song generation** (many sessions, e.g., 4 or more): Use **GPUs with at least 80GB memory**. i.e. H800, A100, or multiple RTX4090s with tensor parallel.

To customize the number of sessions, the interface allows you to specify the desired session count. By default, the model runs **2 sessions** (1 verse + 1 chorus) to avoid OOM issue.

### **Execution Time**
On an **H800 GPU**, generating 30s audio takes **150 seconds**.
On an **RTX 4090 GPU**, generating 30s audio takes approximately **360 seconds**. 

---

## Quickstart
Quick start **VIDEO TUTORIAL** by Fahd: [Link here](https://www.youtube.com/watch?v=RSMNH9GitbA). We recommend watching this video if you are not familiar with machine learning or the command line.

### 1. Install environment and dependencies
Make sure properly install flash attention 2 to reduce VRAM usage. 
```bash
# We recommend using conda to create a new environment.
conda create -n yue python=3.8 # Python >=3.8 is recommended.
conda activate yue
# install cuda >= 11.8
conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia
pip install -r requirements.txt

# For saving GPU memory, FlashAttention 2 is mandatory. 
# Without it, long audio may lead to out-of-memory (OOM) errors.
# Be careful about matching the cuda version and flash-attn version
pip install flash-attn --no-build-isolation
```

### 2. Download the infer code and tokenizer
```bash
# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install
git clone https://github.com/multimodal-art-projection/YuE.git

cd YuE/inference/
git clone https://huggingface.co/m-a-p/xcodec_mini_infer
```

### 3. Run the inference
Now generate music with **YuE** using ğŸ¤— Transformers. Make sure your step [1](#1-install-environment-and-dependencies) and [2](#2-download-the-infer-code-and-tokenizer) are properly set up. 

Note:
- Set `--run_n_segments` to the number of lyric sections if you want to generate a full song. Additionally, you can increase `--stage2_batch_size` based on your available GPU memory.

- You may customize the prompt in `genre.txt` and `lyrics.txt`. See prompt engineering guide [here](#prompt-engineering-guide).

- LM ckpts will be automatically downloaded from huggingface. 


```bash
# This is the CoT mode.
cd YuE/inference/
python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-en-cot \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics.txt \
    --run_n_segments 2 \
    --stage2_batch_size 4 \
    --output_dir ./output \
    --cuda_idx 0 \
    --max_new_tokens 3000 
```

If you want to use music in-context-learning (provide a reference song), enable `--use_audio_prompt`, `--prompt_start_time`, and `--prompt_end_time` to specify the audio segment. 

Note: 
- ICL requires a different ckpt, e.g. `m-a-p/YuE-s1-7B-anneal-en-icl`.

- Music ICL generally requires a 30s audio segment. The model will write new songs with similiar style of the provided audio, and may improve musicality.

- We have 4 modes for ICL: mix, vocal, instrumental, and dual-track. 

- We currently only support mix mode. 

- Dual-track mode work the best, will support in the infer code soon.

```bash
# This is the ICL mode. Currently only mix-ICL is supported.
cd YuE/inference/
python infer.py \
    --stage1_model m-a-p/YuE-s1-7B-anneal-en-icl \
    --stage2_model m-a-p/YuE-s2-1B-general \
    --genre_txt genre.txt \
    --lyrics_txt lyrics.txt \
    --run_n_segments 2 \
    --stage2_batch_size 4 \
    --output_dir ./output \
    --cuda_idx 0 \
    --max_new_tokens 3000 \
    --audio_prompt_path {YOUR_AUDIO_FILE} \
    --prompt_start_time 0 \
    --prompt_end_time 30 
```
---
 
## Prompt Engineering Guide
The prompt consists of three parts: genre tags, lyrics, and ref audio.

### Genre Tagging Prompt
1. An example genre tagging prompt can be found [here](inference/prompt_examples/genre.txt).

2. A stable tagging prompt usually consists of five components: genre, instrument, mood, gender, and timbre. All five should be included if possible, separated by space (space delimiter).

3. Although our tags have an open vocabulary, we have provided the top 200 most commonly used [tags](./top_200_tags.json). It is recommended to select tags from this list for more stable results.

3. The order of the tags is flexible. For example, a stable genre tagging prompt might look like: "inspiring female uplifting pop airy vocal electronic bright vocal vocal."

4. Additionally, we have introduced the "Mandarin" and "Cantonese" tags to distinguish between Mandarin and Cantonese, as their lyrics often share similarities.

### Lyrics Prompt
1. An example lyric prompt can be found [here](inference/prompt_examples/lyrics.txt).

2. We support multiple languages, including but not limited to English, Mandarin Chinese, Cantonese, Japanese, and Korean. The default top language distribution during the annealing phase is revealed in [issue 12](https://github.com/multimodal-art-projection/YuE/issues/12#issuecomment-2620845772). A language ID on a specific annealing checkpoint indicates that we have adjusted the mixing ratio to enhance support for that language.

3. The lyrics prompt should be divided into sessions, with structure labels (e.g., [verse], [chorus], [bridge], [outro]) prepended. Each session should be separated by 2 newline character "\n\n".

4. **DONOT** put too many words in a single segment, since each session is around 30s (`--max_new_tokens 3000` by default).

5. We find that [intro] label is less stable, so we recommend starting with [verse] or [chorus].

6. For generating music with no vocal, see [issue 18](https://github.com/multimodal-art-projection/YuE/issues/18).


### Audio Prompt
1. Audio prompt is optional. Providing ref audio for ICL usually increase the good case rate, and result in less diversity since the generated token space is bounded by the ref audio. CoT only (no ref) will result in a more diverse output.

1. We find that dual-track ICL mode gives the best musicality and prompt following. We will support this mode soon.

2. Use the chorus part of the music as prompt will result in better musicality.

---

## License Agreement \& Disclaimer  
- Our models are licensed under Creative Commons Attribution Non Commercial 4.0, meaning the model weights themselves **CANNOT** be used for commercial purposes.
- However, we **ENCOURAGE** artists and content creators to sample and incorporate outputs generated by our model into their own works, and even monetize them. The only requirement is to credit our name: **YuE by M-A-P**.
- We **DO NOT assume any responsibility** for any misuse of this model, including but not limited to **illegal, malicious, or unethical activities**.  
- Users are solely responsible for any content generated with the model and any consequences arising from its use.  

---

## Citation

If you find our paper and code useful in your research, please consider giving a star :star: and citation :pencil: :)

```BibTeX
@misc{yuan2025yue,
  title={YuE: Open Music Foundation Models for Full-Song Generation},
  author={Ruibin Yuan and Hanfeng Lin and Shawn Guo and Ge Zhang and Jiahao Pan and Yongyi Zang and Haohe Liu and Xingjian Du and Xeron Du and Zhen Ye and Tianyu Zheng and Yinghao Ma and Minghao Liu and Lijun Yu and Zeyue Tian and Ziya Zhou and Liumeng Xue and Xingwei Qu and Yizhi Li and Tianhao Shen and Ziyang Ma and Shangda Wu and Jun Zhan and Chunhui Wang and Yatian Wang and Xiaohuan Zhou and Xiaowei Chi and Xinyue Zhang and Zhenzhu Yang and Yiming Liang and Xiangzhou Wang and Shansong Liu and Lingrui Mei and Peng Li and Yong Chen and Chenghua Lin and Xie Chen and Gus Xia and Zhaoxiang Zhang and Chao Zhang and Wenhu Chen and Xinyu Zhou and Xipeng Qiu and Roger Dannenberg and Jiaheng Liu and Jian Yang and Stephen Huang and Wei Xue and Xu Tan and Yike Guo}, 
  howpublished={\url{https://github.com/multimodal-art-projection/YuE}},
  year={2025},
  note={GitHub repository}
}
```
<br>
